{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\springboard\\\\capstone\\\\springboard-capstone-project\\\\app'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "sent = pd.read_csv('data/sent/all-data.csv', encoding=\"ISO-8859-1\", header=None)\n",
    "sent.columns = ['sent', 'headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = sent.headline.copy()\n",
    "texts = texts.str.replace(\" '\", \"'\")\n",
    "texts = texts.str.replace(\" n't\", \"n't\")\n",
    "texts = texts.str.replace(\"'s \", \" \")\n",
    "texts = text_wrangler.preprocess_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       accord Gran company no plan move production Ru...\n",
       "1       Technopolis plan develop stage area no less sq...\n",
       "2       international electronic industry company Elco...\n",
       "3       new production plant company would increase ca...\n",
       "4       accord company update strategy year Basware ta...\n",
       "                              ...                        \n",
       "4841    LONDON MarketWatch Share price end lower Londo...\n",
       "4842    Rinkuskiai beer sale fall per cent million lit...\n",
       "4843    operate profit fall EUR mn EUR mn include vess...\n",
       "4844    net sale Paper segment decrease EUR mn second ...\n",
       "4845    sale Finland decrease January sale outside Fin...\n",
       "Name: headline, Length: 4846, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent['headline_clean'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 2000\n",
    "max_len = 25\n",
    "train_padded, word_index = text_wrangler.encode_text_into_sequence(texts, num_words, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "target = sent.sent.map({'positive': 1, 'neutral': 0, 'negative': -1})\n",
    "sent_encoded = pd.concat((target, pd.DataFrame(train_padded)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>74</td>\n",
       "      <td>352</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>655</td>\n",
       "      <td>74</td>\n",
       "      <td>94</td>\n",
       "      <td>922</td>\n",
       "      <td>82</td>\n",
       "      <td>178</td>\n",
       "      <td>923</td>\n",
       "      <td>498</td>\n",
       "      <td>1272</td>\n",
       "      <td>...</td>\n",
       "      <td>924</td>\n",
       "      <td>445</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>214</td>\n",
       "      <td>154</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>273</td>\n",
       "      <td>460</td>\n",
       "      <td>757</td>\n",
       "      <td>97</td>\n",
       "      <td>925</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>758</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>25</td>\n",
       "      <td>184</td>\n",
       "      <td>688</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>1273</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>1004</td>\n",
       "      <td>282</td>\n",
       "      <td>13</td>\n",
       "      <td>227</td>\n",
       "      <td>166</td>\n",
       "      <td>427</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>-1</td>\n",
       "      <td>578</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>89</td>\n",
       "      <td>559</td>\n",
       "      <td>578</td>\n",
       "      <td>612</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>403</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>54</td>\n",
       "      <td>291</td>\n",
       "      <td>8</td>\n",
       "      <td>1175</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>-1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>584</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>371</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>459</td>\n",
       "      <td>685</td>\n",
       "      <td>342</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>708</td>\n",
       "      <td>12</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sent    0    1     2    3    4    5    6     7     8  ...    15    16  \\\n",
       "0        0   59    1     3  178   74  352   52    95     1  ...     0     0   \n",
       "1        0  655   74    94  922   82  178  923   498  1272  ...   924   445   \n",
       "2       -1  214  154    75    3  273  460  757    97   925  ...     1   140   \n",
       "3        1   19   52    40    3   83   25  184   688    49  ...   204  1273   \n",
       "4        1   59    3  1004  282   13  227  166   427    10  ...    10     7   \n",
       "...    ...  ...  ...   ...  ...  ...  ...  ...   ...   ...  ...   ...   ...   \n",
       "4841    -1  578    1     9   67   89  559  578   612     1  ...  1168     0   \n",
       "4842     0    1  403     7  121   54  291    8  1175     1  ...     8  1175   \n",
       "4843    -1   27   11   121    2    5    2    5    28   584  ...     0     0   \n",
       "4844    -1   10    7    86  371   90    2    5   102    22  ...   459   685   \n",
       "4845    -1    7   12    90  148    7  708   12   496     0  ...     0     0   \n",
       "\n",
       "       17   18   19  20  21  22  23  24  \n",
       "0       0    0    0   0   0   0   0   0  \n",
       "1       4    0    0   0   0   0   0   0  \n",
       "2     758  687    1  39   0   0   0   0  \n",
       "3      25   52  926   0   0   0   0   0  \n",
       "4       0    0    0   0   0   0   0   0  \n",
       "...   ...  ...  ...  ..  ..  ..  ..  ..  \n",
       "4841    0    0    0   0   0   0   0   0  \n",
       "4842    0    0    0   0   0   0   0   0  \n",
       "4843    0    0    0   0   0   0   0   0  \n",
       "4844  342   60    2   5   2   5   0   0  \n",
       "4845    0    0    0   0   0   0   0   0  \n",
       "\n",
       "[4846 rows x 26 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.to_csv('data/sent/data_clean.csv', index=False)\n",
    "sent_encoded.to_csv('data/sent/data_encoded.csv', index=False)\n",
    "with open(\"data/sent/word_index.json\", \"w\") as outfile:\n",
    "    json.dump(word_index, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.read_csv('data/nyt/nyt.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Addenda: Whitehall Parts Ways With Young & Rub...\n",
       "1                A Famous $35 Emblem Put to Charitable Use\n",
       "2                    Masius Is Enlarging Its New York Shop\n",
       "3               Sara Lee Apparel Unit Selects a New Agency\n",
       "4                                  World Business Briefing\n",
       "                               ...                        \n",
       "80200    Gates Foundation commits more than $2 billion ...\n",
       "80201    Iranian Disinformation Effort Went Small to St...\n",
       "80202    Amazon says the new F.T.C. chair, Lina Khan, s...\n",
       "80203    Didi, the Chinese Ride-Hailing Giant, Makes It...\n",
       "80204    An NFT of the World Wide Web sells for $5.4 mi...\n",
       "Name: headline, Length: 80205, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt.headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80205, 6)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = nyt.dropna(subset=['headline']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80193, 7)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = nyt.headline.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_wrangler.preprocess_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Addenda Whitehall Parts Ways young Rubicam\n",
       "1                         famous Emblem put charitable use\n",
       "2                             Masius enlarge New York Shop\n",
       "3                  Sara Lee Apparel Unit select New Agency\n",
       "4                                  World Business Briefing\n",
       "                               ...                        \n",
       "80188    Gates Foundation commit billion gender equalit...\n",
       "80189    Iranian Disinformation Effort go small stay Bi...\n",
       "80190    Amazon say new FTC chair Lina Khan recuse inve...\n",
       "80191    Didi Chinese RideHailing Giant make Debut Wall...\n",
       "80192                      NFT World Wide Web sell million\n",
       "Name: headline, Length: 80193, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = texts.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt['headline_clean'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 2000\n",
    "max_len = 25\n",
    "train_padded, word_index = text_wrangler.encode_text_into_sequence(texts, num_words, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt.to_csv('data/nyt/data_clean.csv', index=False)\n",
    "sent_clean.to_csv('data/nyt/data_encoded.csv', index=False)\n",
    "with open(\"data/nyt/word_index.json\", \"w\") as outfile:\n",
    "    json.dump(word_index, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practitioner's Guide to Natural Language Processing (Part I) — Processing & Understanding Text  \n",
    "https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
    "\n",
    "NLP – Expand contractions in Text Processing  \n",
    "https://www.geeksforgeeks.org/nlp-expand-contractions-in-text-processing/\n",
    "\n",
    "Text Normalization for Natural Language Processing (NLP)  \n",
    "https://towardsdatascience.com/text-normalization-for-natural-language-processing-nlp-70a314bfa646\n",
    "\n",
    "A hands-on intuitive approach to Deep Learning Methods for Text Data — Word2Vec, GloVe and FastText  \n",
    "https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\n",
    "\n",
    "Tokenization and Text Data Preparation with TensorFlow & Keras  \n",
    "https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
